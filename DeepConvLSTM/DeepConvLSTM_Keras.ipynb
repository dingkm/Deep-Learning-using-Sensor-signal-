{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dQCGfK1MDXH0"
   },
   "source": [
    "### Download and Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5351,
     "status": "ok",
     "timestamp": 1563771736333,
     "user": {
      "displayName": "柯铭",
      "photoUrl": "",
      "userId": "03787419639710019956"
     },
     "user_tz": -540
    },
    "id": "1AtJOnMWDXH1",
    "outputId": "fb460333-f987-499e-9ae3-cb202f164313"
   },
   "outputs": [],
   "source": [
    "#!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00226/OpportunityUCIDataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 395
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 145992,
     "status": "ok",
     "timestamp": 1563771957318,
     "user": {
      "displayName": "柯铭",
      "photoUrl": "",
      "userId": "03787419639710019956"
     },
     "user_tz": -540
    },
    "id": "Tw6mNPm4DXH4",
    "outputId": "a19a5e98-e313-4045-af38-efc5748f63a9"
   },
   "outputs": [],
   "source": [
    "!python preprocess_data.py -i data/OpportunityUCIDataset.zip -o oppChallenge_gestures.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0z-AJb71DXH5"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5TeEMUoDXH6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import _pickle as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Reshape\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten,Input\n",
    "from keras.layers import Dropout,Permute,Lambda\n",
    "from keras.layers.convolutional import Conv1D,Conv2D\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "\n",
    "from sliding_window import sliding_window\n",
    "\n",
    "NB_SENSOR_CHANNELS = 113\n",
    "NUM_CLASSES = 18\n",
    "SLIDING_WINDOW_LENGTH = 24\n",
    "FINAL_SEQUENCE_LENGTH = 8\n",
    "SLIDING_WINDOW_STEP = 12\n",
    "BATCH_SIZE = 128\n",
    "NUM_FILTERS = 64\n",
    "FILTER_SIZE = 5\n",
    "NUM_UNITS_LSTM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SvqSnJENDXH9"
   },
   "source": [
    "### Load the sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1892,
     "status": "ok",
     "timestamp": 1563772183646,
     "user": {
      "displayName": "柯铭",
      "photoUrl": "",
      "userId": "03787419639710019956"
     },
     "user_tz": -540
    },
    "id": "bJqF-abUDXH9",
    "outputId": "0a7b35d7-c114-4068-bcf8-0e703c096f0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      " ..from file data/oppChallenge_gestures.data\n",
      " ..reading instances: train (557963, 113), test (118750, 113)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(filename):\n",
    "\n",
    "    f = open(filename, 'rb')\n",
    "    data = cp.load(f)\n",
    "    f.close()\n",
    "\n",
    "    X_train, y_train = data[0]\n",
    "    X_test, y_test = data[1]\n",
    "\n",
    "    print(\" ..from file {}\".format(filename))\n",
    "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # The targets are casted to int8 for GPU compatibility.\n",
    "    y_train = y_train.astype(np.uint8)\n",
    "    y_test = y_test.astype(np.uint8)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X_train, y_train, X_test, y_test = load_dataset('data/oppChallenge_gestures.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0DjUpr04DXIA"
   },
   "source": [
    "### Segmentation and Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1563772192067,
     "user": {
      "displayName": "柯铭",
      "photoUrl": "",
      "userId": "03787419639710019956"
     },
     "user_tz": -540
    },
    "id": "7sJW5he_DXIA",
    "outputId": "26f13726-1a11-425d-a2db-5d9e98541355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ..after sliding and reshaping, train data: inputs (46495, 24, 113), targets (46495, 18)\n",
      " ..after sliding and reshaping, test data : inputs (9894, 24, 113), targets (9894, 18)\n"
     ]
    }
   ],
   "source": [
    "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x, (ws, data_x.shape[1]), (ss, 1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y, ws, ss)])\n",
    "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
    "\n",
    "# Sensor data is segmented using a sliding window mechanism\n",
    "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "\n",
    "# Data is reshaped\n",
    "X_train = X_train.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)) # for input to Conv1D\n",
    "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)) # for input to Conv1D\n",
    "y_train = np_utils.to_categorical(y_train) # one-hot encoding\n",
    "y_test = np_utils.to_categorical(y_test) # one-hot encoding\n",
    "\n",
    "print(\" ..after sliding and reshaping, train data: inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
    "print(\" ..after sliding and reshaping, test data : inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uEb8q1jDXIC"
   },
   "source": [
    "![](https://github.com/yminoh/DeepConvLSTM_Python3/raw/master/architecture_of_DeepConvLSTM.png)  \n",
    "<div style=\"text-align: center\">Figure 3 from Ordonez and Roggen, 2016</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9DBM2RWuDXIC"
   },
   "source": [
    "### Build and train the Kears layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 757
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1336,
     "status": "ok",
     "timestamp": 1563772202454,
     "user": {
      "displayName": "柯铭",
      "photoUrl": "",
      "userId": "03787419639710019956"
     },
     "user_tz": -540
    },
    "id": "ePEvw7hQDXID",
    "outputId": "1182d905-6088-4c7e-db66-1220a7448f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of input  (?, 24, 113)\n",
      "shape after conv2d1  (?, 64, 20, 113)\n",
      "shape after conv2d2  (?, 64, 16, 113)\n",
      "shape before permute  (?, 64, 8, 113)\n",
      "shape after permute  (?, 8, 64, 113)\n",
      "shape before LSTM  (?, 8, 7232)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input2 (InputLayer)          (None, 24, 113)           0         \n",
      "_________________________________________________________________\n",
      "reshape_21 (Reshape)         (None, 1, 24, 113)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 64, 20, 113)       384       \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 64, 16, 113)       20544     \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 64, 12, 113)       20544     \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 64, 8, 113)        20544     \n",
      "_________________________________________________________________\n",
      "permute_7 (Permute)          (None, 8, 64, 113)        0         \n",
      "_________________________________________________________________\n",
      "reshape_22 (Reshape)         (None, 8, 7232)           0         \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 8, 128)            3768832   \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 8, 128)            131584    \n",
      "_________________________________________________________________\n",
      "reshape_23 (Reshape)         (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "lambda_7 (Lambda)            (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 18)                2322      \n",
      "=================================================================\n",
      "Total params: 3,964,754\n",
      "Trainable params: 3,964,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rmp = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "inputs = Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS), name='input2')\n",
    "print('shape of input ',inputs.shape)\n",
    "outputs = Reshape((1,SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS))(inputs)\n",
    "outputs = Conv2D(NUM_FILTERS,kernel_size=[FILTER_SIZE, 1],\n",
    "        strides=(1, 1), padding='VALID', activation=None, data_format = 'channels_first')(outputs)\n",
    "print('shape after conv2d1 ',outputs.shape)\n",
    "outputs = Conv2D(NUM_FILTERS,kernel_size=[FILTER_SIZE, 1],\n",
    "        strides=(1, 1), padding='VALID', activation=None, data_format='channels_first')(outputs)\n",
    "print('shape after conv2d2 ',outputs.shape)\n",
    "outputs = Conv2D(NUM_FILTERS,kernel_size=[FILTER_SIZE, 1],\n",
    "        strides=(1, 1), padding='VALID', activation=None, data_format='channels_first')(outputs)\n",
    "outputs = Conv2D(NUM_FILTERS,kernel_size=[FILTER_SIZE, 1],\n",
    "        strides=(1, 1), padding='VALID', activation=None, data_format='channels_first')(outputs)\n",
    "print('shape before permute ',outputs.shape)\n",
    "\n",
    "outputs = Permute((2,1,3))(outputs)\n",
    "print('shape after permute ',outputs.shape)\n",
    "outputs = Reshape((8,64*113))(outputs)\n",
    "print('shape before LSTM ',outputs.shape)\n",
    "outputs = LSTM(NUM_UNITS_LSTM,return_sequences=True)(outputs)\n",
    "outputs = LSTM(NUM_UNITS_LSTM,return_sequences=True)(outputs)\n",
    "outputs = Reshape((-1, NUM_UNITS_LSTM))(outputs)\n",
    "\n",
    "def reduce_dim(x):\n",
    "    return x[:,-1:,:]\n",
    "\n",
    "outputs = Lambda(reduce_dim)(outputs)\n",
    "outputs = Flatten()(outputs)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax')(outputs)\n",
    "# outputs = Reshape((-1, NUM_CLASSES))(outputs)\n",
    "\n",
    "# def reduce_dim(x):\n",
    "#     return x[:,-1:,1]\n",
    "\n",
    "# outputs = Lambda(reduce_dim)(outputs)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "#adam = keras.optimizers.Adam(lr=0.001, beta_1=0.5, beta_2=0.9, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=rmp, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gsqppKIVDXIF"
   },
   "source": [
    "![](https://github.com/yminoh/DeepConvLSTM_Python3/raw/master/Table1.png)  \n",
    "<div style=\"text-align: center\">Table 1 from Ordonez and Roggen, 2016</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 227541,
     "status": "ok",
     "timestamp": 1563772441486,
     "user": {
      "displayName": "柯铭",
      "photoUrl": "",
      "userId": "03787419639710019956"
     },
     "user_tz": -540
    },
    "id": "BU6PQt56DXIG",
    "outputId": "ab761de3-f2d0-4723-e087-7374ce726d9e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 09:41:16.038125  7460 deprecation.py:323] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37196 samples, validate on 9299 samples\n",
      "Epoch 1/10\n",
      "37196/37196 [==============================] - 47s 1ms/step - loss: 1.5022 - acc: 0.6740 - val_loss: 3.6234 - val_acc: 0.0139\n",
      "Epoch 2/10\n",
      "37196/37196 [==============================] - 41s 1ms/step - loss: 1.5016 - acc: 0.6719 - val_loss: 1.1475 - val_acc: 0.7736\n",
      "Epoch 3/10\n",
      "37196/37196 [==============================] - 40s 1ms/step - loss: 1.4914 - acc: 0.6763 - val_loss: 1.1397 - val_acc: 0.7736\n",
      "Epoch 4/10\n",
      "37196/37196 [==============================] - 39s 1ms/step - loss: 1.4909 - acc: 0.6763 - val_loss: 1.1582 - val_acc: 0.7736\n",
      "Epoch 5/10\n",
      "37196/37196 [==============================] - 40s 1ms/step - loss: 1.4908 - acc: 0.6763 - val_loss: 1.1554 - val_acc: 0.7736\n",
      "Epoch 6/10\n",
      "37196/37196 [==============================] - 41s 1ms/step - loss: 1.4905 - acc: 0.6763 - val_loss: 1.1490 - val_acc: 0.7736\n",
      "Epoch 7/10\n",
      "37196/37196 [==============================] - 41s 1ms/step - loss: 1.4902 - acc: 0.6763 - val_loss: 1.1557 - val_acc: 0.7736\n",
      "Epoch 8/10\n",
      "37196/37196 [==============================] - 42s 1ms/step - loss: 1.4905 - acc: 0.6763 - val_loss: 1.1730 - val_acc: 0.7736\n",
      "Epoch 9/10\n",
      "37196/37196 [==============================] - 41s 1ms/step - loss: 1.4904 - acc: 0.6763 - val_loss: 1.1608 - val_acc: 0.7736\n",
      "Epoch 10/10\n",
      "37196/37196 [==============================] - 41s 1ms/step - loss: 1.4899 - acc: 0.6763 - val_loss: 1.1495 - val_acc: 0.7736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x119046d8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.2, \n",
    "          epochs=10, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wsGJUjZdDXII"
   },
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3669,
     "status": "ok",
     "timestamp": 1563772538981,
     "user": {
      "displayName": "柯铭",
      "photoUrl": "",
      "userId": "03787419639710019956"
     },
     "user_tz": -540
    },
    "id": "dhxbYZwEDXII",
    "outputId": "da6e2832-017b-47b5-99b0-766762efda35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "test_true = np.argmax(y_test, axis=1)\n",
    "np.unique(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 818,
     "status": "ok",
     "timestamp": 1563772543077,
     "user": {
      "displayName": "柯铭",
      "photoUrl": "",
      "userId": "03787419639710019956"
     },
     "user_tz": -540
    },
    "id": "El-OfTOcDXIK",
    "outputId": "f67fd19f-7575-4b7a-8224-513b492d00d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest fscore:\t0.7564 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "print(\"\\tTest fscore:\\t{:.4f} \".format(metrics.f1_score(test_true, test_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "        \n",
    "# Classification of the testing data\n",
    "print(\"Processing {0} instances in mini-batches of {1}\".format(X_test.shape[0],BATCH_SIZE))\n",
    "test_pred = np.empty((0))\n",
    "test_true = np.empty((0))\n",
    "start_time = time.time()\n",
    "for batch in iterate_minibatches(X_test, y_test, BATCH_SIZE):\n",
    "    inputs, targets = batch\n",
    "    y_pred, = test_fn(inputs)\n",
    "    test_pred = np.append(test_pred, y_pred, axis=0)\n",
    "    test_true = np.append(test_true, targets, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DeepConvLSTM_Keras.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
