{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import _pickle as cp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Reshape\n",
    "import keras.backend as K\n",
    "from keras.layers.recurrent import GRU,LSTM\n",
    "from keras.layers import GRUCell,Lambda\n",
    "from keras.layers import RNN\n",
    "from keras import regularizers\n",
    "\n",
    "from sliding_window2 import sliding_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0     acc_x     acc_y     acc_z    gyro_x    gyro_y    gyro_z\n",
      "0           0 -6.090849  0.565032  7.623138 -0.006109  0.010690 -0.006720\n",
      "1           1 -6.090849  0.593762  7.603985  0.001222  0.011301 -0.006414\n",
      "2           2 -6.100426  0.612916  7.651869  0.000305  0.015577 -0.008247\n",
      "3           3 -6.033388  0.603339  7.651869  0.004581  0.007941 -0.000611\n",
      "4           4 -6.081272  0.641646  7.671022  0.013134  0.015577 -0.001527\n",
      "(2548244, 6)\n",
      "acc_x     0\n",
      "acc_y     0\n",
      "acc_z     0\n",
      "gyro_x    0\n",
      "gyro_y    0\n",
      "gyro_z    0\n",
      "dtype: int64\n",
      "   bike  sit  stairsdown  stairsup  stand  walk\n",
      "0     0    0           0         0      1     0\n",
      "1     0    0           0         0      1     0\n",
      "2     0    0           0         0      1     0\n",
      "3     0    0           0         0      1     0\n",
      "4     0    0           0         0      1     0\n",
      "(2400000, 6)\n",
      "(100000, 144) (100000, 144)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "NB_SENSOR_CHANNELS =  6 # originla 6\n",
    "NUM_CLASSES = 6\n",
    "SLIDING_WINDOW_LENGTH = 24 #original 24\n",
    "FINAL_SEQUENCE_LENGTH = 8\n",
    "SLIDING_WINDOW_STEP = 12\n",
    "BATCH_SIZE = 100\n",
    "NUM_FILTERS = 64\n",
    "FILTER_SIZE = 5\n",
    "NUM_UNITS_LSTM = 128\n",
    "\n",
    "df = pd.read_csv('all_raw_data.csv')\n",
    "print(df.head())\n",
    "df.drop('Unnamed: 0',axis='columns',inplace=True)\n",
    "# df.rename(columns={ 'x_g.1':'z_g'}, inplace = True)\n",
    "print(df.shape)\n",
    "\n",
    "# df.dropna(subset=['Index','gt'], inplace=True)\n",
    "print(df.isnull().sum(axis=0))\n",
    "\n",
    "x_train = df\n",
    "y_train = pd.read_csv('all_label.csv')\n",
    "y_train.drop('Unnamed: 0',axis='columns',inplace=True)\n",
    "print(y_train.head())\n",
    "x_train = x_train.iloc[:2400000].values\n",
    "print(x_train.shape)\n",
    "y_train = y_train.iloc[:2400000].values\n",
    "x_train = x_train.reshape((-1,6*24))\n",
    "y_train = y_train.reshape((-1,6*24))\n",
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a.shape, ws and ss must all have the same length. They were [2, 1, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-d92962906ce8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Sensor data is segmented using a sliding window mechanism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopp_sliding_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSLIDING_WINDOW_LENGTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSLIDING_WINDOW_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopp_sliding_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSLIDING_WINDOW_LENGTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSLIDING_WINDOW_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-d92962906ce8>\u001b[0m in \u001b[0;36mopp_sliding_window\u001b[1;34m(data_x, data_y, ws, ss)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mopp_sliding_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdata_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msliding_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdata_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msliding_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\DeepSense-master\\DeepSense-master\\sliding_window2.py\u001b[0m in \u001b[0;36msliding_window\u001b[1;34m(a, ws, ss, flatten)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         raise ValueError(\\\n\u001b[1;32m---> 68\u001b[1;33m         'a.shape, ws and ss must all have the same length. They were %s' % str(ls))\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;31m# ensure that ws is smaller than a in every dimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: a.shape, ws and ss must all have the same length. They were [2, 1, 1]"
     ]
    }
   ],
   "source": [
    "\n",
    "assert NB_SENSOR_CHANNELS == x_train.shape[1]\n",
    "def opp_sliding_window(data_x, data_y, ws, ss):\n",
    "    data_x = sliding_window(data_x, (ws, data_x.shape[1]), (ss, 1))\n",
    "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y, ws, ss)])\n",
    "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
    "\n",
    "# Sensor data is segmented using a sliding window mechanism\n",
    "x_train, y_train = opp_sliding_window(x_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "x_test, y_test = opp_sliding_window(x_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
    "\n",
    "# Data is reshaped\n",
    "x_train = x_train.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)) # for input to Conv1D\n",
    "x_test = x_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS)) # for input to Conv1D\n",
    "y_train = np_utils.to_categorical(y_train) # one-hot encoding\n",
    "y_test = np_utils.to_categorical(y_test) # one-hot encoding\n",
    "\n",
    "print(\" ..after sliding and reshaping, train data: inputs {0}, targets {1}\".format(x_train.shape, y_train.shape))\n",
    "print(\" ..after sliding and reshaping, test data : inputs {0}, targets {1}\".format(x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0906 15:00:23.258462  2908 deprecation_wrapper.py:119] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0906 15:00:23.275463  2908 deprecation_wrapper.py:119] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0906 15:00:23.277464  2908 deprecation_wrapper.py:119] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0906 15:00:23.865497  2908 deprecation_wrapper.py:119] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0906 15:00:23.879498  2908 deprecation_wrapper.py:119] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 24, 6)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 24, 64)            18176     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 24, 64)            33024     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 9222      \n",
      "=================================================================\n",
      "Total params: 60,422\n",
      "Trainable params: 60,422\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 64 # Hidden layer num of features\n",
    "n_classes = 6 # Total classes (should go up, or should go down)\n",
    "\n",
    "\n",
    "# Training \n",
    "\n",
    "learning_rate = 0.015\n",
    "lambda_loss_amount = 0.015\n",
    "batch_size = 1500\n",
    "display_iter = 30000  # To show test set accuracy during training\n",
    "\n",
    "\n",
    "sensor_input = Input(shape=(24,6), name='input')\n",
    "outputs = LSTM(n_hidden,unit_forget_bias=True,return_sequences=True)(sensor_input)\n",
    "outputs = LSTM(n_hidden,unit_forget_bias=True,return_sequences=True)(outputs)\n",
    "\n",
    "# def reduce_dim(x):\n",
    "#     return x[:,-1:,:]\n",
    "\n",
    "# outputs = Lambda(reduce_dim)(outputs)\n",
    "outputs = Activation('linear')(outputs)\n",
    "outputs = Flatten()(outputs)\n",
    "\n",
    "outputs = Dense(6, activation='softmax',kernel_regularizer=regularizers.l2(lambda_loss_amount))(outputs)\n",
    "# keras.regularizers.l2(lambda_loss_amount)\n",
    "adam = keras.optimizers.Adam(lr=learning_rate,epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model = Model(inputs=sensor_input, outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "      optimizer=adam,\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "#model.fit([acc_inputs,gyro_inputs], train_y, batch_size=64, epochs=10)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0906 15:00:24.088510  2908 deprecation.py:323] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0906 15:00:25.635599  2908 deprecation_wrapper.py:119] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114770 samples, validate on 28693 samples\n",
      "Epoch 1/10\n",
      "114770/114770 [==============================] - 159s 1ms/step - loss: 1.4858 - acc: 0.3659 - val_loss: 1.2865 - val_acc: 0.4818\n",
      "Epoch 2/10\n",
      "114770/114770 [==============================] - 156s 1ms/step - loss: 1.2623 - acc: 0.4886 - val_loss: 1.2200 - val_acc: 0.5116\n",
      "Epoch 3/10\n",
      "114770/114770 [==============================] - 157s 1ms/step - loss: 1.2212 - acc: 0.5134 - val_loss: 1.2228 - val_acc: 0.5193\n",
      "Epoch 4/10\n",
      "114770/114770 [==============================] - 157s 1ms/step - loss: 1.1934 - acc: 0.5291 - val_loss: 1.1806 - val_acc: 0.5335\n",
      "Epoch 5/10\n",
      "114770/114770 [==============================] - 158s 1ms/step - loss: 1.1746 - acc: 0.5394 - val_loss: 1.1612 - val_acc: 0.5447\n",
      "Epoch 6/10\n",
      "114770/114770 [==============================] - 158s 1ms/step - loss: 1.1537 - acc: 0.5503 - val_loss: 1.1558 - val_acc: 0.5531\n",
      "Epoch 7/10\n",
      "114770/114770 [==============================] - 157s 1ms/step - loss: 1.1553 - acc: 0.5539 - val_loss: 1.1777 - val_acc: 0.5486\n",
      "Epoch 8/10\n",
      "114770/114770 [==============================] - 156s 1ms/step - loss: 1.1311 - acc: 0.5636 - val_loss: 1.1348 - val_acc: 0.5626\n",
      "Epoch 9/10\n",
      "114770/114770 [==============================] - 156s 1ms/step - loss: 1.1260 - acc: 0.5658 - val_loss: 1.1185 - val_acc: 0.5693\n",
      "Epoch 10/10\n",
      "114770/114770 [==============================] - 158s 1ms/step - loss: 1.1151 - acc: 0.5731 - val_loss: 1.1301 - val_acc: 0.5621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x119f39b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=128,validation_split=0.2, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    " \n",
    "model.save('LSTM_keras_raw.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# del model  # deletes the existing model\n",
    " \n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "# model = load_model('LSTM_keras_raw.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "70660/70660 [==============================] - 29s 414us/step\n",
      "loss, acc  1.1338554639368195 0.5594820266062837\n",
      "70660/70660 [==============================] - 29s 405us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.64      0.59     13129\n",
      "           1       0.67      0.81      0.74     13417\n",
      "           2       0.71      0.55      0.62     12899\n",
      "           3       0.50      0.56      0.53     10856\n",
      "           4       0.45      0.34      0.38     10690\n",
      "           5       0.40      0.36      0.38      9669\n",
      "\n",
      "   micro avg       0.56      0.56      0.56     70660\n",
      "   macro avg       0.54      0.54      0.54     70660\n",
      "weighted avg       0.56      0.56      0.55     70660\n",
      " samples avg       0.56      0.56      0.56     70660\n",
      "\n",
      "0.5525567748281338\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "test_x = x_test\n",
    "test_y = y_test\n",
    "\n",
    "# print ( \"Loss = \" + str( preds[0] ) )\n",
    "# print ( \"Test Accuracy = \" + str( preds[1] ) )\n",
    "print(model.metrics_names)\n",
    "loss, acc = model.evaluate(test_x, test_y, batch_size=128)\n",
    "print('loss, acc ',loss,acc)\n",
    "\n",
    "\n",
    "y_pred = model.predict(test_x, batch_size=128, verbose=1)\n",
    "# y_pred_bool = np.argmax(preds, axis=1)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "        max_value=max(y_pred[i])\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if max_value==y_pred[i][j]:\n",
    "                y_pred[i][j]=1\n",
    "            else:\n",
    "                y_pred[i][j]=0\n",
    "\n",
    "print(classification_report(test_y, y_pred))\n",
    "print(metrics.f1_score(test_y, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
