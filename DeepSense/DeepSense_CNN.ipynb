{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "SEPCTURAL_SAMPLES = 10\n",
    "FEATURE_DIM = SEPCTURAL_SAMPLES*6*2  #120\n",
    "CONV_LEN = 3\n",
    "CONV_LEN_INTE = 3#4\n",
    "CONV_LEN_LAST = 3#5\n",
    "CONV_NUM = 64\n",
    "CONV_MERGE_LEN = 8\n",
    "CONV_MERGE_LEN2 = 6\n",
    "CONV_MERGE_LEN3 = 4\n",
    "CONV_NUM2 = 64\n",
    "INTER_DIM = 128\n",
    "OUT_DIM = 6#len(idDict)\n",
    "WIDE = 20\n",
    "CONV_KEEP_PROB = 0.2\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "TOTAL_ITER_NUM = 1000\n",
    "\n",
    "select = 'a'\n",
    "\n",
    "metaDict = {'a':[119080, 1193], 'b':[116870, 1413], 'c':[116020, 1477]}\n",
    "TRAIN_SIZE = metaDict[select][0]\n",
    "EVAL_DATA_SIZE = metaDict[select][1]\n",
    "EVAL_ITER_NUM = int(math.ceil(EVAL_DATA_SIZE / BATCH_SIZE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119080, 20, 120) (119080, 6)\n",
      "(1193, 20, 120) (1193, 6)\n",
      "(119080, 20, 60, 1) (119080, 20, 60, 1)\n",
      "[0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "###### Import training data\n",
    "train_x = np.load('DeepSense_data/train_x.npy')\n",
    "train_y = np.load('DeepSense_data/train_y.npy')\n",
    "eval_x = np.load('DeepSense_data/eval_x.npy')\n",
    "eval_y = np.load('DeepSense_data/eval_y.npy')\n",
    "\n",
    "# train_x = np.array(train_x)\n",
    "print(train_x.shape,train_y.shape)\n",
    "print(eval_x.shape,eval_y.shape)\n",
    "\n",
    "acc,gyo = np.split(train_x,2)\n",
    "acc = acc.reshape((-1,20,60,1))\n",
    "gyo = gyo.reshape((-1,20,60,1))\n",
    "print(acc.shape,gyo.shape)\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254000, 120)\n",
      "(12700, 20, 120) (12700, 6)\n",
      "(12700, 20, 60, 1) (12700, 20, 60, 1)\n",
      "[0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "###### Import training data\n",
    "train_x = np.load('fre_data.npy')\n",
    "print(train_x.shape)\n",
    "train_y = np.load('fre_data_label.npy')\n",
    "# eval_x = np.load('DeepSense_data/eval_x.npy')\n",
    "# eval_y = np.load('DeepSense_data/eval_y.npy')\n",
    "train_x = train_x.reshape((-1,20,120))\n",
    "\n",
    "# train_x = np.array(train_x)\n",
    "print(train_x.shape,train_y.shape)\n",
    "# print(eval_x.shape,eval_y.shape)\n",
    "\n",
    "acc,gyo = np.split(train_x,2)\n",
    "acc = acc.reshape((-1,20,60,1))\n",
    "gyo = gyo.reshape((-1,20,60,1))\n",
    "print(acc.shape,gyo.shape)\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Input\n",
    "from keras import optimizers\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.layers import Reshape\n",
    "import keras.backend as K\n",
    "from keras.layers.recurrent import GRU,LSTM\n",
    "from keras.layers import GRUCell,Lambda\n",
    "from keras.layers import RNN\n",
    "from keras import regularizers\n",
    "# from keras.backend import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0913 14:55:41.738993  9080 deprecation_wrapper.py:119] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0913 14:55:41.759994  9080 deprecation_wrapper.py:119] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0913 14:55:41.761994  9080 deprecation_wrapper.py:119] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0913 14:55:41.798996  9080 deprecation_wrapper.py:119] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0913 14:55:41.800996  9080 deprecation_wrapper.py:119] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_inputs.shape,gyro_inputs.shape  (12700, 20, 60, 1) (12700, 20, 60, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 14:55:43.422089  9080 deprecation_wrapper.py:119] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0913 14:55:43.529095  9080 deprecation.py:506] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_conv3_shape [None, 20, 14, 64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 14:55:44.711163  9080 deprecation_wrapper.py:119] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input1 (InputLayer)          (None, 20, 120, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 18, 64)        1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 20, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 20, 16, 64)        12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 20, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 20, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 14, 64)        12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 20, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 20, 896)           0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 20, 128)           393600    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 20, 128)           98688     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 15366     \n",
      "=================================================================\n",
      "Total params: 534,342\n",
      "Trainable params: 533,958\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "acc_inputs, gyro_inputs = acc,gyo\n",
    "print('acc_inputs.shape,gyro_inputs.shape ',acc_inputs.shape,gyro_inputs.shape)\n",
    "\n",
    "input1 = Input(shape=(20,120,1), name='input1')\n",
    "# sensor_inputs shape (BATCH_SIZE, WIDE, FEATURE_DIM, CHANNEL=1)\n",
    "acc_conv1 = Conv2D(CONV_NUM, kernel_size=[1, 2*3*CONV_LEN],\n",
    "        strides=(1, 2*3), padding='VALID', activation=None, data_format='channels_last')(input1)\n",
    "acc_conv1 = BatchNormalization()(acc_conv1)\n",
    "acc_conv1 = Activation('relu')(acc_conv1)\n",
    "acc_conv1_shape = acc_conv1.get_shape().as_list()\n",
    "acc_conv1 = Dropout(CONV_KEEP_PROB, noise_shape=[acc_conv1_shape[0], 1, 1, acc_conv1_shape[3]], seed=None)(acc_conv1)\n",
    "#         layers.dropout(acc_conv1, CONV_KEEP_PROB, is_training=train,\n",
    "#             noise_shape=[acc_conv1_shape[0], 1, 1, acc_conv1_shape[3]], scope='acc_dropout1')\n",
    "\n",
    "acc_conv2 = Conv2D(CONV_NUM, kernel_size=[1, CONV_LEN_INTE],\n",
    "        strides=(1, 1), padding='VALID', activation=None, data_format='channels_last')(acc_conv1)\n",
    "acc_conv2 = BatchNormalization()(acc_conv2)\n",
    "acc_conv2 = Activation('relu')(acc_conv2)\n",
    "acc_conv2_shape = acc_conv2.get_shape().as_list()\n",
    "acc_conv2 = Dropout(CONV_KEEP_PROB, noise_shape=[acc_conv2_shape[0], 1, 1, acc_conv2_shape[3]], seed=None)(acc_conv2)\n",
    "#layers.dropout(acc_conv2, CONV_KEEP_PROB, is_training=train,\n",
    "#             noise_shape=[acc_conv2_shape[0], 1, 1, acc_conv2_shape[3]], scope='acc_dropout2')\n",
    "\n",
    "acc_conv3 = Conv2D(CONV_NUM, kernel_size=[1, CONV_LEN_LAST],\n",
    "        strides=(1, 1), padding='VALID', activation=None, data_format='channels_last')(acc_conv2)\n",
    "acc_conv3 = BatchNormalization()(acc_conv3)\n",
    "acc_conv3 = Activation('relu')(acc_conv3)\n",
    "acc_conv3_shape = acc_conv3.get_shape().as_list()\n",
    "print('acc_conv3_shape',acc_conv3_shape)\n",
    "outputs = Reshape((acc_conv3_shape[1], -1))(acc_conv3)\n",
    "# tf.reshape(acc_conv3, [acc_conv3_shape[0], acc_conv3_shape[1], 1, acc_conv3_shape[2],acc_conv3_shape[3]])\n",
    "#print('acc_conv_out.shape ',acc_conv_out.shape)\n",
    "outputs = GRU(INTER_DIM, activation='tanh',dropout=0.5,return_sequences=True)(outputs)\n",
    "outputs = Dropout(0.5)(outputs)\n",
    "outputs = GRU(INTER_DIM, activation='tanh',dropout=0.5,return_sequences=True)(outputs)\n",
    "outputs = Dropout(0.5)(outputs)\n",
    "outputs = Flatten()(outputs)\n",
    "outputs = Dense(6, activation='softmax',kernel_regularizer=regularizers.l2(5e-3))(outputs)\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.5, beta_2=0.9, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model = Model(inputs=input1, outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "      optimizer=adam,\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "#model.fit([acc_inputs,gyro_inputs], train_y, batch_size=64, epochs=10)\n",
    "model.summary()\n",
    "\n",
    "# sensor_conv_in = concatenate([acc_conv_out, gyro_conv_out], axis=2)\n",
    "# # print('sensor_conv_in ',sensor_conv_in)\n",
    "# senor_conv_shape = sensor_conv_in.get_shape().as_list()\n",
    "# sensor_conv_in = Dropout(CONV_KEEP_PROB, noise_shape=[senor_conv_shape[0], 1, 1, 1, senor_conv_shape[4]],seed=None)(sensor_conv_in)\n",
    "# print('sensor_conv_in ',sensor_conv_in)\n",
    "\n",
    "# sensor_conv1 = Conv3D(CONV_NUM2, kernel_size=[1, 2, CONV_MERGE_LEN],\n",
    "#                 strides=(1, 1, 1), padding='SAME', activation=None, data_format='channels_last')(sensor_conv_in)\n",
    "# sensor_conv1 = BatchNormalization()(sensor_conv1)\n",
    "# sensor_conv1 = Activation('relu')(sensor_conv1)\n",
    "# sensor_conv1_shape = sensor_conv1.get_shape().as_list()\n",
    "# sensor_conv1 = Dropout(CONV_KEEP_PROB, noise_shape=[sensor_conv1_shape[0], 1, 1, 1, sensor_conv1_shape[4]], seed=None)(sensor_conv1)\n",
    "\n",
    "# sensor_conv2 = Conv3D(CONV_NUM2, kernel_size=[1, 2, CONV_MERGE_LEN2],\n",
    "#                 strides=(1, 1, 1), padding='SAME', activation=None, data_format='channels_last')(sensor_conv1)\n",
    "# sensor_conv2 = BatchNormalization()(sensor_conv2)\n",
    "# sensor_conv2 = Activation('relu')(sensor_conv2)\n",
    "# sensor_conv2_shape = sensor_conv2.get_shape().as_list()\n",
    "# sensor_conv2 = Dropout(CONV_KEEP_PROB, \n",
    "#                        noise_shape=[sensor_conv2_shape[0], 1, 1, 1, sensor_conv2_shape[4]])(sensor_conv2)\n",
    "\n",
    "# sensor_conv3 = Conv3D(CONV_NUM2, kernel_size=[1, 2, CONV_MERGE_LEN3],\n",
    "#                 strides=(1, 1, 1), padding='SAME', activation=None, data_format='channels_last')(sensor_conv2)\n",
    "# sensor_conv3 = BatchNormalization()(sensor_conv3)\n",
    "# sensor_conv3 = Activation('relu')(sensor_conv3)\n",
    "# sensor_conv3_shape = sensor_conv3.get_shape().as_list()\n",
    "# print('sensor_conv3.shape ',sensor_conv3_shape)\n",
    "# sensor_conv_out = Reshape(([sensor_conv3_shape[1], sensor_conv3_shape[2]*sensor_conv3_shape[3]*sensor_conv3_shape[4]]))(sensor_conv3)\n",
    "# #  tf.reshape(sensor_conv3, [sensor_conv3_shape[0], sensor_conv3_shape[1], sensor_conv3_shape[2]*sensor_conv3_shape[3]*sensor_conv3_shape[4]])\n",
    "# print('sensor_conv_out.shape ',sensor_conv_out.shape)\n",
    "# # outputs = Flatten()(sensor_conv_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0913 14:56:23.383163  9080 deprecation.py:323] From C:\\Users\\AYA04_Intern\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8128 samples, validate on 2032 samples\n",
      "Epoch 1/20\n",
      "8128/8128 [==============================] - 29s 4ms/step - loss: 1.5152 - acc: 0.4065 - val_loss: 0.9117 - val_acc: 0.6924\n",
      "Epoch 2/20\n",
      "8128/8128 [==============================] - 24s 3ms/step - loss: 0.9191 - acc: 0.6489 - val_loss: 0.5342 - val_acc: 0.8056\n",
      "Epoch 3/20\n",
      "8128/8128 [==============================] - 24s 3ms/step - loss: 0.6834 - acc: 0.7480 - val_loss: 0.4632 - val_acc: 0.8337\n",
      "Epoch 4/20\n",
      "8128/8128 [==============================] - 25s 3ms/step - loss: 0.5317 - acc: 0.8097 - val_loss: 0.2588 - val_acc: 0.9203\n",
      "Epoch 5/20\n",
      "8128/8128 [==============================] - 25s 3ms/step - loss: 0.3963 - acc: 0.8612 - val_loss: 0.1985 - val_acc: 0.9478\n",
      "Epoch 6/20\n",
      "8128/8128 [==============================] - 25s 3ms/step - loss: 0.3232 - acc: 0.8951 - val_loss: 0.2842 - val_acc: 0.9154\n",
      "Epoch 7/20\n",
      "8128/8128 [==============================] - 25s 3ms/step - loss: 0.2697 - acc: 0.9186 - val_loss: 0.1360 - val_acc: 0.9641\n",
      "Epoch 8/20\n",
      "8128/8128 [==============================] - 24s 3ms/step - loss: 0.2279 - acc: 0.9313 - val_loss: 0.1438 - val_acc: 0.9646\n",
      "Epoch 9/20\n",
      "8128/8128 [==============================] - 24s 3ms/step - loss: 0.1964 - acc: 0.9408 - val_loss: 0.1441 - val_acc: 0.9631\n",
      "Epoch 10/20\n",
      "8128/8128 [==============================] - 25s 3ms/step - loss: 0.1706 - acc: 0.9526 - val_loss: 0.0955 - val_acc: 0.9833\n",
      "Epoch 11/20\n",
      "8128/8128 [==============================] - 25s 3ms/step - loss: 0.1468 - acc: 0.9600 - val_loss: 0.0830 - val_acc: 0.9828\n",
      "Epoch 12/20\n",
      "8128/8128 [==============================] - 25s 3ms/step - loss: 0.1333 - acc: 0.9647 - val_loss: 0.1002 - val_acc: 0.9769\n",
      "Epoch 13/20\n",
      "8128/8128 [==============================] - 25s 3ms/step - loss: 0.1239 - acc: 0.9664 - val_loss: 0.0758 - val_acc: 0.9843\n",
      "Epoch 14/20\n",
      "8128/8128 [==============================] - 25s 3ms/step - loss: 0.1175 - acc: 0.9680 - val_loss: 0.0717 - val_acc: 0.9887\n",
      "Epoch 15/20\n",
      "8128/8128 [==============================] - 25s 3ms/step - loss: 0.1043 - acc: 0.9726 - val_loss: 0.0856 - val_acc: 0.9808\n",
      "Epoch 16/20\n",
      "8128/8128 [==============================] - 25s 3ms/step - loss: 0.0997 - acc: 0.9732 - val_loss: 0.0764 - val_acc: 0.9833\n",
      "Epoch 17/20\n",
      "8128/8128 [==============================] - 25s 3ms/step - loss: 0.0916 - acc: 0.9781 - val_loss: 0.0581 - val_acc: 0.9867\n",
      "Epoch 18/20\n",
      "8128/8128 [==============================] - 24s 3ms/step - loss: 0.0828 - acc: 0.9771 - val_loss: 0.0728 - val_acc: 0.9882\n",
      "Epoch 19/20\n",
      "8128/8128 [==============================] - 24s 3ms/step - loss: 0.0825 - acc: 0.9775 - val_loss: 0.0783 - val_acc: 0.9843\n",
      "Epoch 20/20\n",
      "8128/8128 [==============================] - 24s 3ms/step - loss: 0.0792 - acc: 0.9802 - val_loss: 0.0604 - val_acc: 0.9877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x4bfb6390>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape((-1,20,120,1))\n",
    "model.fit(x_train, y_train, batch_size=64,validation_split=0.2, epochs=20,callbacks=[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    " \n",
    "model.save('DeepSense_CNN.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "# del model  # deletes the existing model\n",
    " \n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#model = load_model('DeepSense_keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "2540/2540 [==============================] - 1s 480us/step\n",
      "loss, acc  0.07137528294184077 0.9842519679407435\n",
      "2540/2540 [==============================] - 2s 596us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       386\n",
      "           1       0.99      1.00      0.99       500\n",
      "           2       0.98      0.96      0.97       358\n",
      "           3       0.98      0.97      0.98       399\n",
      "           4       0.99      1.00      0.99       417\n",
      "           5       0.97      0.98      0.97       480\n",
      "\n",
      "   micro avg       0.98      0.99      0.98      2540\n",
      "   macro avg       0.98      0.98      0.98      2540\n",
      "weighted avg       0.98      0.99      0.98      2540\n",
      " samples avg       0.98      0.99      0.98      2540\n",
      "\n",
      "0.9815384530524908\n",
      "[[384   1   0   0   1   0]\n",
      " [  0 499   0   0   1   0]\n",
      " [  2   0 342   3   0  11]\n",
      " [  9   0   2 386   0   2]\n",
      " [  0   1   0   0 416   0]\n",
      " [  1   0   2   5   0 472]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "test_x = x_test.reshape((-1,20,120,1))\n",
    "test_y = y_test\n",
    "# test_x = np.array(test_x)\n",
    "# test_y = np.array(test_y)\n",
    "\n",
    "# print ( \"Loss = \" + str( preds[0] ) )\n",
    "# print ( \"Test Accuracy = \" + str( preds[1] ) )\n",
    "print(model.metrics_names)\n",
    "loss, acc = model.evaluate(test_x,test_y, batch_size=128)\n",
    "print('loss, acc ',loss,acc)\n",
    "\n",
    "\n",
    "y_pred = model.predict(test_x, batch_size=128, verbose=1)\n",
    "y_pred = (y_pred > 0.5) \n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "        max_value=max(y_pred[i])\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if max_value==y_pred[i][j]:\n",
    "                y_pred[i][j]=1\n",
    "            else:\n",
    "                y_pred[i][j]=0\n",
    "\n",
    "print(classification_report(test_y, y_pred))\n",
    "print(metrics.f1_score(test_y, y_pred, average=\"weighted\"))\n",
    "print(confusion_matrix(test_y.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch': [], 'epoch': []}\n",
    "        self.accuracy = {'batch': [], 'epoch': []}\n",
    "        self.val_loss = {'batch': [], 'epoch': []}\n",
    "        self.val_acc = {'batch': [], 'epoch': []}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('acc'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        #创建一个图\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')#plt.plot(x,y)，这个将数据画成曲线\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)#设置网格形式\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')#给x，y轴加注释\n",
    "        plt.legend(loc=\"upper right\")#设置图例显示位置\n",
    "        plt.show()\n",
    "\n",
    "history = LossHistory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LossHistory' object has no attribute 'losses'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-aa1da9555a98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-220b40b855bb>\u001b[0m in \u001b[0;36mloss_plot\u001b[1;34m(self, loss_type)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mloss_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0miters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;31m#创建一个图\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LossHistory' object has no attribute 'losses'"
     ]
    }
   ],
   "source": [
    "history.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
